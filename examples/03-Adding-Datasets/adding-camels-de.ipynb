{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray\n",
    "\n",
    "from neuralhydrology.datasetzoo.basedataset import BaseDataset\n",
    "from neuralhydrology.utils.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sngrj0hn/GitHub/neuralhydrology/examples/03-Adding-Datasets'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wd to wkspce root\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamelsDE(BaseDataset):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 cfg: Config,\n",
    "                 is_train: bool,\n",
    "                 period: str,\n",
    "                 basin: str = None,\n",
    "                 additional_features: List[Dict[str, pd.DataFrame]] = [],\n",
    "                 id_to_int: Dict[str, int] = {},\n",
    "                 scaler: Dict[str, Union[pd.Series, xarray.DataArray]] = {}):\n",
    "        \n",
    "        # Initialize `BaseDataset` class\n",
    "        super(CamelsDE, self).__init__(cfg=cfg,\n",
    "                                       is_train=is_train,\n",
    "                                       period=period,\n",
    "                                       basin=basin,\n",
    "                                       additional_features=additional_features,\n",
    "                                       id_to_int=id_to_int,\n",
    "                                       scaler=scaler)\n",
    "\n",
    "    def _load_basin_data(self, basin: str) -> pd.DataFrame:\n",
    "        \"\"\"Load timeseries data of one specific basin\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _load_attributes(self) -> pd.DataFrame:\n",
    "        \"\"\"Load catchment attributes\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading functions\n",
    "\n",
    "For all datasets, we implemented the actual data loading (e.g., from the txt or csv files) in separate functions outside of the class so that these functions are usable everywhere. This is useful for example when you want to inspect or visualize the discharge of a particular basin or do anything else with the basin data. These functions are implemented within the same file (since they are specific to each data set) and we use those functions from within the class methods.\n",
    "\n",
    "So let's start by implementing a function that reads a single basin file of time series data for a given basin identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_camels_de_timeseries(data_dir: Path, basin: str) -> pd.DataFrame:\n",
    "    preprocessed_dir = data_dir / \"timeseries\"\n",
    "    \n",
    "    # make sure the CAMELS-CL data was already preprocessed and per-basin files exist.\n",
    "    if not preprocessed_dir.is_dir():\n",
    "        msg = [\n",
    "            f\"No preprocessed data directory found at {preprocessed_dir}.\"\n",
    "        ]\n",
    "        raise FileNotFoundError(\"\".join(msg))\n",
    "        \n",
    "    # load the data for the specific basin into a time-indexed dataframe\n",
    "    basin_file = preprocessed_dir / f\"CAMELS_DE_hydromet_timeseries_DE{basin}.csv\"\n",
    "    df = pd.read_csv(basin_file, index_col='date', parse_dates=['date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of this should be easy to follow. First we check that the data was already preprocessed and if it wasn't, we throw an appropriate error message. Then we proceed to load the data into a pd.DataFrame and we make sure that the index is converted into a datetime format.\n",
    "\n",
    "Next, we need a function to load the attributes, which are stored in a file called `1_CAMELScl_attributes.txt`. We assume that this file exist in the root directory of the dataset (such information is useful to add to the docstring!). The dataframe that this function has to return must be basin-indexed with attributes as columns. Furthermore, we accept an optional argument `basins`, which is a list of strings. This list can specify basins of interest and if passed, we only return the attributes for said basins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_camels_de_attributes(data_dir: Path, basins: List[str] = []) -> pd.DataFrame:\n",
    "    \n",
    "    attributes_path = data_dir\n",
    "\n",
    "    if not attributes_path.exists():\n",
    "        raise FileNotFoundError(f\"Attribute folder not found at {attributes_path}\")\n",
    "\n",
    "    txt_files = attributes_path.glob('*_attributes.csv')\n",
    "\n",
    "    # Read-in attributes into one big dataframe\n",
    "    dfs = []\n",
    "    for txt_file in txt_files:\n",
    "        df_temp = pd.read_csv(txt_file, sep=',', header=0, dtype={'gauge_id': str})\n",
    "        df_temp = df_temp.set_index('gauge_id')\n",
    "\n",
    "        dfs.append(df_temp)\n",
    "\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "\n",
    "\n",
    "    if basins:\n",
    "        if any(b not in df.index for b in basins):\n",
    "            raise ValueError('Some basins are missing static attributes.')\n",
    "        df = df.loc[basins]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_mean</th>\n",
       "      <th>p_seasonality</th>\n",
       "      <th>frac_snow</th>\n",
       "      <th>high_prec_freq</th>\n",
       "      <th>high_prec_dur</th>\n",
       "      <th>high_prec_timing</th>\n",
       "      <th>low_prec_freq</th>\n",
       "      <th>low_prec_dur</th>\n",
       "      <th>low_prec_timing</th>\n",
       "      <th>aquitard_perc</th>\n",
       "      <th>...</th>\n",
       "      <th>flow_perc_complete</th>\n",
       "      <th>slope_fdc</th>\n",
       "      <th>hfd_mean</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q95</th>\n",
       "      <th>high_q_freq</th>\n",
       "      <th>high_q_dur</th>\n",
       "      <th>low_q_freq</th>\n",
       "      <th>low_q_dur</th>\n",
       "      <th>zero_q_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gauge_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DE110000</th>\n",
       "      <td>2.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15.23</td>\n",
       "      <td>1.19</td>\n",
       "      <td>djf</td>\n",
       "      <td>202.67</td>\n",
       "      <td>3.71</td>\n",
       "      <td>son</td>\n",
       "      <td>67.06</td>\n",
       "      <td>...</td>\n",
       "      <td>98.072</td>\n",
       "      <td>2.08</td>\n",
       "      <td>151.33</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4.48</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.07</td>\n",
       "      <td>22.70</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110010</th>\n",
       "      <td>2.87</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>13.30</td>\n",
       "      <td>1.19</td>\n",
       "      <td>jja</td>\n",
       "      <td>178.97</td>\n",
       "      <td>3.72</td>\n",
       "      <td>son</td>\n",
       "      <td>64.11</td>\n",
       "      <td>...</td>\n",
       "      <td>98.240</td>\n",
       "      <td>2.59</td>\n",
       "      <td>145.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.89</td>\n",
       "      <td>37.71</td>\n",
       "      <td>6.27</td>\n",
       "      <td>170.48</td>\n",
       "      <td>31.39</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110020</th>\n",
       "      <td>2.54</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15.22</td>\n",
       "      <td>1.18</td>\n",
       "      <td>jja</td>\n",
       "      <td>212.80</td>\n",
       "      <td>3.74</td>\n",
       "      <td>son</td>\n",
       "      <td>32.41</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.21</td>\n",
       "      <td>161.39</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.45</td>\n",
       "      <td>8.39</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110030</th>\n",
       "      <td>2.45</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15.23</td>\n",
       "      <td>1.17</td>\n",
       "      <td>jja</td>\n",
       "      <td>213.89</td>\n",
       "      <td>3.74</td>\n",
       "      <td>son</td>\n",
       "      <td>25.30</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.72</td>\n",
       "      <td>166.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110040</th>\n",
       "      <td>2.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.07</td>\n",
       "      <td>17.16</td>\n",
       "      <td>1.18</td>\n",
       "      <td>jja</td>\n",
       "      <td>223.92</td>\n",
       "      <td>3.75</td>\n",
       "      <td>son</td>\n",
       "      <td>22.35</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>178.06</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10580</th>\n",
       "      <td>2.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15.20</td>\n",
       "      <td>1.17</td>\n",
       "      <td>jja</td>\n",
       "      <td>220.52</td>\n",
       "      <td>4.01</td>\n",
       "      <td>son</td>\n",
       "      <td>46.60</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.01</td>\n",
       "      <td>155.33</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1.54</td>\n",
       "      <td>12.42</td>\n",
       "      <td>6.59</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10590</th>\n",
       "      <td>2.21</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>14.65</td>\n",
       "      <td>1.17</td>\n",
       "      <td>jja</td>\n",
       "      <td>216.96</td>\n",
       "      <td>4.01</td>\n",
       "      <td>son</td>\n",
       "      <td>54.13</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.07</td>\n",
       "      <td>157.14</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.52</td>\n",
       "      <td>1.62</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.35</td>\n",
       "      <td>6.55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10600</th>\n",
       "      <td>1.62</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>17.31</td>\n",
       "      <td>1.17</td>\n",
       "      <td>jja</td>\n",
       "      <td>245.11</td>\n",
       "      <td>4.01</td>\n",
       "      <td>son</td>\n",
       "      <td>30.80</td>\n",
       "      <td>...</td>\n",
       "      <td>84.524</td>\n",
       "      <td>2.71</td>\n",
       "      <td>178.57</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5.66</td>\n",
       "      <td>3.60</td>\n",
       "      <td>31.28</td>\n",
       "      <td>15.37</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10610</th>\n",
       "      <td>1.80</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.09</td>\n",
       "      <td>17.32</td>\n",
       "      <td>1.17</td>\n",
       "      <td>jja</td>\n",
       "      <td>242.87</td>\n",
       "      <td>4.01</td>\n",
       "      <td>son</td>\n",
       "      <td>97.87</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.51</td>\n",
       "      <td>168.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.71</td>\n",
       "      <td>16.96</td>\n",
       "      <td>5.37</td>\n",
       "      <td>55.46</td>\n",
       "      <td>6.49</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10620</th>\n",
       "      <td>1.94</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>16.32</td>\n",
       "      <td>1.17</td>\n",
       "      <td>jja</td>\n",
       "      <td>229.77</td>\n",
       "      <td>4.01</td>\n",
       "      <td>son</td>\n",
       "      <td>21.36</td>\n",
       "      <td>...</td>\n",
       "      <td>99.128</td>\n",
       "      <td>2.10</td>\n",
       "      <td>163.57</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.99</td>\n",
       "      <td>6.37</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1555 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          p_mean  p_seasonality  frac_snow  high_prec_freq  high_prec_dur  \\\n",
       "gauge_id                                                                    \n",
       "DE110000    2.97           0.01       0.12           15.23           1.19   \n",
       "DE110010    2.87           0.05       0.12           13.30           1.19   \n",
       "DE110020    2.54           0.19       0.10           15.22           1.18   \n",
       "DE110030    2.45           0.25       0.09           15.23           1.17   \n",
       "DE110040    2.61           0.40       0.07           17.16           1.18   \n",
       "...          ...            ...        ...             ...            ...   \n",
       "DEG10580    2.29           0.09       0.09           15.20           1.17   \n",
       "DEG10590    2.21           0.06       0.10           14.65           1.17   \n",
       "DEG10600    1.62           0.15       0.08           17.31           1.17   \n",
       "DEG10610    1.80           0.31       0.09           17.32           1.17   \n",
       "DEG10620    1.94           0.10       0.08           16.32           1.17   \n",
       "\n",
       "         high_prec_timing  low_prec_freq  low_prec_dur low_prec_timing  \\\n",
       "gauge_id                                                                 \n",
       "DE110000              djf         202.67          3.71             son   \n",
       "DE110010              jja         178.97          3.72             son   \n",
       "DE110020              jja         212.80          3.74             son   \n",
       "DE110030              jja         213.89          3.74             son   \n",
       "DE110040              jja         223.92          3.75             son   \n",
       "...                   ...            ...           ...             ...   \n",
       "DEG10580              jja         220.52          4.01             son   \n",
       "DEG10590              jja         216.96          4.01             son   \n",
       "DEG10600              jja         245.11          4.01             son   \n",
       "DEG10610              jja         242.87          4.01             son   \n",
       "DEG10620              jja         229.77          4.01             son   \n",
       "\n",
       "          aquitard_perc  ...  flow_perc_complete  slope_fdc  hfd_mean    Q5  \\\n",
       "gauge_id                 ...                                                  \n",
       "DE110000          67.06  ...              98.072       2.08    151.33  0.28   \n",
       "DE110010          64.11  ...              98.240       2.59    145.16  0.00   \n",
       "DE110020          32.41  ...             100.000       2.21    161.39  0.19   \n",
       "DE110030          25.30  ...             100.000       1.72    166.16  0.26   \n",
       "DE110040          22.35  ...             100.000       0.86    178.06  0.55   \n",
       "...                 ...  ...                 ...        ...       ...   ...   \n",
       "DEG10580          46.60  ...             100.000       2.01    155.33  0.24   \n",
       "DEG10590          54.13  ...             100.000       2.07    157.14  0.21   \n",
       "DEG10600          30.80  ...              84.524       2.71    178.57  0.03   \n",
       "DEG10610          97.87  ...             100.000       2.51    168.25  0.07   \n",
       "DEG10620          21.36  ...              99.128       2.10    163.57  0.15   \n",
       "\n",
       "           Q95  high_q_freq  high_q_dur  low_q_freq  low_q_dur  zero_q_freq  \n",
       "gauge_id                                                                     \n",
       "DE110000  4.48         3.83        2.07       22.70       6.84         0.00  \n",
       "DE110010  2.89        37.71        6.27      170.48      31.39         0.39  \n",
       "DE110020  2.41         1.99        2.45        8.39       6.81         0.00  \n",
       "DE110030  2.13         0.33        1.92        0.91       9.00         0.00  \n",
       "DE110040  2.19         0.43        1.11        0.04       1.00         0.00  \n",
       "...        ...          ...         ...         ...        ...          ...  \n",
       "DEG10580  2.90         2.68        1.54       12.42       6.59         0.00  \n",
       "DEG10590  2.52         1.62        2.87        8.35       6.55         0.00  \n",
       "DEG10600  0.79         5.66        3.60       31.28      15.37         0.00  \n",
       "DEG10610  1.71        16.96        5.37       55.46       6.49         0.00  \n",
       "DEG10620  1.67         3.34        1.99        6.37       3.61         0.00  \n",
       "\n",
       "[1555 rows x 106 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_camels_de_attributes(data_dir = Path('./data/camels_de'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamelsCL(BaseDataset):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 cfg: Config,\n",
    "                 is_train: bool,\n",
    "                 period: str,\n",
    "                 basin: str = None,\n",
    "                 additional_features: List[Dict[str, pd.DataFrame]] = [],\n",
    "                 id_to_int: Dict[str, int] = {},\n",
    "                 scaler: Dict[str, Union[pd.Series, xarray.DataArray]] = {}):\n",
    "        \n",
    "        # Initialize `BaseDataset` class\n",
    "        super(CamelsCL, self).__init__(cfg=cfg,\n",
    "                                       is_train=is_train,\n",
    "                                       period=period,\n",
    "                                       basin=basin,\n",
    "                                       additional_features=additional_features,\n",
    "                                       id_to_int=id_to_int,\n",
    "                                       scaler=scaler)\n",
    "\n",
    "    def _load_basin_data(self, basin: str) -> pd.DataFrame:\n",
    "        \"\"\"Load timeseries data of one specific basin\"\"\"\n",
    "        return load_camels_de_timeseries(data_dir=self.cfg.data_dir, basin=basin)\n",
    "\n",
    "    def _load_attributes(self) -> pd.DataFrame:\n",
    "        \"\"\"Load catchment attributes\"\"\"\n",
    "        return load_camels_de_attributes(self.cfg.data_dir, basins=self.basins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating the dataset class into NeuralHydrology\n",
    "\n",
    "With these few lines of code, you are ready to use a new dataset within the NeuralHydrology framework. The only thing missing is to link the new dataset in the `get_dataset()` function, implemented in `neuralhydrology.datasetzoo.__init__.py`. Again, we removed the doc-string for brevity ([here](https://neuralhydrology.readthedocs.io/en/latest/api/neuralhydrology.datasetzoo.html#neuralhydrology.datasetzoo.get_dataset) you can find the documentation), but the code of this function is as simple as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralhydrology.datasetzoo.basedataset import BaseDataset\n",
    "from neuralhydrology.datasetzoo.camelscl import CamelsCL\n",
    "from neuralhydrology.datasetzoo.camelsgb import CamelsGB\n",
    "from neuralhydrology.datasetzoo.camelsus import CamelsUS\n",
    "from neuralhydrology.datasetzoo.camelsde import CamelsDE\n",
    "from neuralhydrology.datasetzoo.hourlycamelsus import HourlyCamelsUS\n",
    "from neuralhydrology.utils.config import Config\n",
    "\n",
    "\n",
    "def get_dataset(cfg: Config,\n",
    "                is_train: bool,\n",
    "                period: str,\n",
    "                basin: str = None,\n",
    "                additional_features: list = [],\n",
    "                id_to_int: dict = {},\n",
    "                scaler: dict = {}) -> BaseDataset:\n",
    "    \n",
    "    # check config argument and select appropriate data set class\n",
    "    if cfg.dataset == \"camels_us\":\n",
    "        Dataset = CamelsUS\n",
    "    elif cfg.dataset == \"camels_gb\":\n",
    "        Dataset = CamelsGB\n",
    "    elif cfg.dataset == \"hourly_camels_us\":\n",
    "        Dataset = HourlyCamelsUS\n",
    "    elif cfg.dataset == \"camels_cl\":\n",
    "        Dataset = CamelsCL\n",
    "    elif cfg.dataset == \"camels_de\":\n",
    "        Dataset = CamelsDE\n",
    "    else:\n",
    "        raise NotImplementedError(f\"No dataset class implemented for dataset {cfg.dataset}\")\n",
    "    \n",
    "    # initialize dataset\n",
    "    ds = Dataset(cfg=cfg,\n",
    "                 is_train=is_train,\n",
    "                 period=period,\n",
    "                 basin=basin,\n",
    "                 additional_features=additional_features,\n",
    "                 id_to_int=id_to_int,\n",
    "                 scaler=scaler)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, by settig `dataset: camels_cl` in the config file, you are able to train a model on the CAMELS-CL data set. \n",
    "\n",
    "The available time series features are:\n",
    "- tmax_cr2met\n",
    "- precip_mswep\n",
    "- streamflow_m3s\n",
    "- tmin_cr2met\n",
    "- pet_8d_modis\n",
    "- precip_chirps\n",
    "- pet_hargreaves\n",
    "- streamflow_mm\n",
    "- precip_cr2met\n",
    "- swe\n",
    "- tmean_cr2met\n",
    "- precip_tmpa\n",
    "\n",
    "For a list of available attributes, look at the `1_CAMELScl_attributes.txt` file or make use of the above implemented function to load the attributes into a pd.DataFrame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
