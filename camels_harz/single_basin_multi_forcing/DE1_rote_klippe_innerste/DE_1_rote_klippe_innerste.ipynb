{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from neuralhydrology.utils.configutils import create_config_files\n",
    "from neuralhydrology.nh_run_scheduler import schedule_runs\n",
    "from neuralhydrology.evaluation.tuning import generate_run_dir_patterns\n",
    "from neuralhydrology.evaluation.tuning import get_best_model_per_seed\n",
    "from neuralhydrology.nh_run import eval_run\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform two stage hyperparametertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Stage**: \n",
    "   - Use three repetitions of each hyperparameter setting with different random seeds for initializing the weights.\n",
    "   - All models are run for 100 epochs using the Adam optimizer with:\n",
    "     - Learning rate: 5eâˆ’3\n",
    "     - Batch size: 256\n",
    "   - During training, the model is validated after every 4 epochs on validation period data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid for first stage\n",
    "grid1 = {\n",
    "    'hidden_size': [8, 16, 32, 64],  # Hidden size\n",
    "    'output_dropout': [0.0, 0.2, 0.4, 0.5],  # Dropout rate on the head layer\n",
    "    'seed': [123, 999, 321]  # Use three repetitions of each hyperparameter setting with different random seeds\n",
    "}\n",
    "# Create configs for all possible parameter combinations\n",
    "create_config_files(base_config_path=Path('base_stage1.yml'), modify_dict=grid1, output_dir=Path('configs_stage1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for all configs from one call of the first stage\n",
    "schedule_runs(mode='train', directory=Path('configs_stage1'), gpu_ids=[0], runs_per_gpu=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get run directories for the first stage\n",
    "run_patterns = generate_run_dir_patterns(grid1, 'single_basin_multi_forcing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model for each seed\n",
    "best_models_per_seed = get_best_model_per_seed(parent_dir='runs', seeds=grid1['seed'], grid_params=list(grid1.keys())[:-1], run_patterns=run_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print epoch, median NSE, and hyperparameters for each seed\n",
    "def print_grid_parameters(best_models_per_seed, grid_params):\n",
    "    for seed, result in best_models_per_seed.items():\n",
    "        if result['best_model_config'] is not None:\n",
    "            config = result['best_model_config']\n",
    "            params = {k: config.get(k) for k in grid_params if k in config}\n",
    "            print(f\"Seed: {seed}\")\n",
    "            print(f\"Best epoch: {result['best_epoch']}\")\n",
    "            print(f\"Best median NSE score: {result['best_nse']}\")\n",
    "            print(f\"Parameters: {params}\")\n",
    "            print()\n",
    "print_grid_parameters(best_models_per_seed, list(grid1.keys())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose overall best model and hyperparameters based on median NSE for stage 1 and write parameters to a dictionary\n",
    "best_model = None\n",
    "best_nse = -float('inf')\n",
    "best_seed = None\n",
    "best_params1 = None\n",
    "\n",
    "for seed, result in best_models_per_seed.items():\n",
    "    if result['best_nse'] > best_nse:\n",
    "        best_nse = result['best_nse']\n",
    "        best_model = result['best_model_dir']\n",
    "        # best params excluding the seed\n",
    "        best_params1 = {k: v for k, v in result['best_model_config'].items() if k in grid1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Stage**: \n",
    "   - Using the hyperparameters chosen from the first stage, we tune the learning rate and batch size  in a similar way, maximizing over the median NSE over 3 model repetitions.\n",
    "   - All models are run again for 100 epochs using the Adam optimizer.\n",
    "   - During training, the model is validated after every 4 epochs on validation period data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config file for the second stage including hyperparameters of the best model from the first stage\n",
    "# Read in the base.yml file and replace the hyperparameters with the best hyperparameters from the first stage\n",
    "with open('base_stage1.yml', 'r') as file:\n",
    "    base_config = yaml.safe_load(file)\n",
    "\n",
    "# Update the base config with the best hyperparameters from the first stage\n",
    "base_config.update(best_params1)\n",
    "\n",
    "# Save updated config to a new file\n",
    "with open('base_stage2.yml', 'w') as file:\n",
    "    yaml.dump(base_config, file)\n",
    "\n",
    "# Create grid for second stage\n",
    "grid2 = {\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],  # Learning rate\n",
    "    'batch_size': [32, 64, 128],  # Batch size\n",
    "    'seed': [123, 999, 321]  # Use three repetitions of each hyperparameter setting with different random seeds\n",
    "}\n",
    "\n",
    "create_config_files(base_config_path=Path('base_stage2.yml'), modify_dict=grid2, output_dir=Path('configs_stage2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for all configs from one call of stage 2\n",
    "schedule_runs(mode='train', directory=Path('configs_stage2'), gpu_ids=[0], runs_per_gpu=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get run directories for the second stage\n",
    "run_patterns = generate_run_dir_patterns(grid2, 'single_basin_multi_forcing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model for each seed\n",
    "best_models_per_seed = get_best_model_per_seed(parent_dir='runs', seeds=grid2['seed'], grid_params=list(grid2.keys())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print epoch, median NSE, and hyperparameters for each seed\n",
    "print_grid_parameters(best_models_per_seed, list(grid2.keys())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose overall best model and hyperparameters based on median NSE for stage 2 and write parameters to a dictionary\n",
    "best_model = None\n",
    "best_nse = -float('inf')\n",
    "best_seed = None\n",
    "best_params2 = None\n",
    "\n",
    "for seed, result in best_models_per_seed.items():\n",
    "    if result['best_nse'] > best_nse:\n",
    "        best_nse = result['best_nse']\n",
    "        best_model = result['best_model_dir']\n",
    "        best_epoch = f\"{result['best_epoch']}\"\n",
    "        # best params excluding the seed\n",
    "        best_params2 = {k: v for k, v in result['best_model_config'].items() if k in grid2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config file for the second stage including hyperparameters of the best model from the first stage\n",
    "# Read in the base.yml file and replace the hyperparameters with the best hyperparameters from the first stage\n",
    "with open('base_stage2.yml', 'r') as file:\n",
    "    base_config = yaml.safe_load(file)\n",
    "\n",
    "# Update the base config with the best hyperparameters from the first stage\n",
    "base_config.update(best_params2)\n",
    "\n",
    "# Save the updated config to a new file\n",
    "with open('base_final.yml', 'w') as file:\n",
    "    yaml.dump(base_config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate run on test set\n",
    "The path to the best model is automatically saved in the variable best_model, and the corresponding best epoch is stored as a string in best_epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_run(run_dir=best_model, period=\"test\", epoch=best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and inspect model predictions\n",
    "Load the results file and compare the model predictions with observations. The results file is always a pickled dictionary with one key per basin (even for a single basin). The next-lower dictionary level is the temporal resolution of the predictions. In this case, we trained a model only on daily data ('1D'). Within the temporal resolution, the next-lower dictionary level are `xr`(an xarray Dataset that contains observations and predictions), as well as one key for each metric that was specified in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(best_model / \"test\" / f\"model_epoch0{best_epoch}\" / \"test_results.p\", \"rb\") as fp:\n",
    "    results = pickle.load(fp)\n",
    "    \n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['DE1']['1D']['xr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract observations and simulations\n",
    "qobs = results['DE1']['1D']['xr']['discharge_vol_obs']\n",
    "qsim = results['DE1']['1D']['xr']['discharge_vol_sim']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "ax.plot(qobs['date'], qobs)\n",
    "ax.plot(qsim['date'], qsim)\n",
    "ax.set_ylabel(\"Discharge (mm/d)\")\n",
    "ax.set_title(f\"Test period - NSE {results['DE1']['1D']['NSE']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
